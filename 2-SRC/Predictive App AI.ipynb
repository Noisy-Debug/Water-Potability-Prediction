{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "executionInfo": {
     "elapsed": 238801,
     "status": "ok",
     "timestamp": 1743195752128,
     "user": {
      "displayName": "TEJAS BHANARKAR",
      "userId": "00418776055484818104"
     },
     "user_tz": 0
    },
    "id": "VHIp5ln2dTEa",
    "outputId": "87ca8fe4-67b5-4df7-eb14-5a72e7e47f72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://4b220d8cdd68bbc469.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    }
   ],
   "source": [
    "# ===================== Imports ===================== #\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization, Conv1D, MaxPooling1D, Flatten, Add\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "# ===================== Data Loading & Preprocessing ===================== #\n",
    "df = pd.read_csv(\"1-DATA/Water_Potability.csv\")\n",
    "df = pd.DataFrame(SimpleImputer(strategy='mean').fit_transform(df), columns=df.columns)\n",
    "\n",
    "X = df.drop(\"Potability\", axis=1)\n",
    "y = df[\"Potability\"]\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X, y = SMOTE().fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=100)\n",
    "X_train_cnn = X_train.reshape(-1, X.shape[1], 1)\n",
    "X_test_cnn = X_test.reshape(-1, X.shape[1], 1)\n",
    "\n",
    "# ===================== Model Training ===================== #\n",
    "\n",
    "# --- XGBoost --- #\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=5)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_probs = xgb_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_xgb = (xgb_probs > 0.5).astype(int)\n",
    "\n",
    "# --- MLP --- #\n",
    "mlp = Sequential([\n",
    "    Input(shape=(X.shape[1],)),\n",
    "    Dense(128, activation='relu'), Dropout(0.3),\n",
    "    Dense(64, activation='relu'), Dropout(0.3),\n",
    "    Dense(32, activation='relu'), Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "mlp.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "mlp_probs = mlp.predict(X_test).flatten()\n",
    "y_pred_mlp = (mlp_probs > 0.5).astype(int)\n",
    "\n",
    "# --- CNN --- #\n",
    "cnn = Sequential([\n",
    "    Input(shape=(X.shape[1], 1)),\n",
    "    Conv1D(64, 3, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Conv1D(64, 3, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'), Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "cnn.fit(X_train_cnn, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "cnn_probs = cnn.predict(X_test_cnn).flatten()\n",
    "y_pred_cnn = (cnn_probs > 0.5).astype(int)\n",
    "\n",
    "# --- DNN --- #\n",
    "dnn = Sequential([\n",
    "    Input(shape=(X.shape[1],)),\n",
    "    Dense(256, activation='relu'), BatchNormalization(), Dropout(0.4),\n",
    "    Dense(128, activation='relu'), BatchNormalization(), Dropout(0.4),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "dnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "dnn.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "dnn_probs = dnn.predict(X_test).flatten()\n",
    "y_pred_dnn = (dnn_probs > 0.5).astype(int)\n",
    "\n",
    "# --- ResNet Model --- #\n",
    "def build_resnet(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Dense(128, activation=\"relu\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    res = Dense(128, activation=\"relu\")(x)\n",
    "    res = BatchNormalization()(res)\n",
    "    res = Dense(128, activation=\"relu\")(res)\n",
    "    res = BatchNormalization()(res)\n",
    "\n",
    "    x = Add()([x, res])\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "\n",
    "    return Model(inputs, Dense(1, activation=\"sigmoid\")(x))\n",
    "\n",
    "resnet = build_resnet((X.shape[1],))\n",
    "resnet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "resnet.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "resnet_probs = resnet.predict(X_test).flatten()\n",
    "y_pred_resnet = (resnet_probs > 0.5).astype(int)\n",
    "\n",
    "# ===================== Evaluation ===================== #\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Model\": [\"XGBoost\", \"MLP\", \"CNN\", \"DNN\", \"ResNet\"],\n",
    "    \"Accuracy\": [accuracy_score(y_test, y_pred_xgb), accuracy_score(y_test, y_pred_mlp),\n",
    "                 accuracy_score(y_test, y_pred_cnn), accuracy_score(y_test, y_pred_dnn),\n",
    "                 accuracy_score(y_test, y_pred_resnet)],\n",
    "    \"Precision\": [precision_score(y_test, y_pred_xgb), precision_score(y_test, y_pred_mlp),\n",
    "                  precision_score(y_test, y_pred_cnn), precision_score(y_test, y_pred_dnn),\n",
    "                  precision_score(y_test, y_pred_resnet)],\n",
    "    \"Recall\": [recall_score(y_test, y_pred_xgb), recall_score(y_test, y_pred_mlp),\n",
    "               recall_score(y_test, y_pred_cnn), recall_score(y_test, y_pred_dnn),\n",
    "               recall_score(y_test, y_pred_resnet)],\n",
    "    \"F1 Score\": [f1_score(y_test, y_pred_xgb), f1_score(y_test, y_pred_mlp),\n",
    "                 f1_score(y_test, y_pred_cnn), f1_score(y_test, y_pred_dnn),\n",
    "                 f1_score(y_test, y_pred_resnet)],\n",
    "    \"AUC\": [roc_auc_score(y_test, xgb_probs), roc_auc_score(y_test, mlp_probs),\n",
    "            roc_auc_score(y_test, cnn_probs), roc_auc_score(y_test, dnn_probs),\n",
    "            roc_auc_score(y_test, resnet_probs)],\n",
    "})\n",
    "metrics_df.iloc[:, 1:] = metrics_df.iloc[:, 1:].round(3)\n",
    "\n",
    "# ===================== Gemini API Setup ===================== #\n",
    "try:\n",
    "    genai.configure(api_key=\"AIzaSyAkMfxEHg0MszPh1kQABp-U9MQCTMw-Mro\")  # Replace with your actual key\n",
    "    model_gemini = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "except Exception:\n",
    "    model_gemini = None\n",
    "\n",
    "# ===================== Prompts & Gemini Responses ===================== #\n",
    "summary = metrics_df.to_string(index=False)\n",
    "predefined_prompts = {\n",
    "    \"Explain model performance\": f\"\"\"\n",
    "I trained 5 models (XGBoost, MLP, CNN, DNN, ResNet) to classify water potability. Here's the summary:\n",
    "\n",
    "{summary}\n",
    "\n",
    "Can you explain what these results mean in simple terms?\n",
    "\"\"\",\n",
    "    \"Which model is best and why?\": f\"\"\"\n",
    "Based on the following model performance metrics, which model would you recommend?\n",
    "\n",
    "{summary}\n",
    "\n",
    "Explain which one is best and why, in terms of generalization and real-world use.\n",
    "\"\"\",\n",
    "    \"Suggest how to improve the weakest model\": f\"\"\"\n",
    "Below is a summary of model performance on water potability classification:\n",
    "\n",
    "{summary}\n",
    "\n",
    "Which model performed the worst, and what strategies could I use to improve its performance?\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "precomputed_responses = {}\n",
    "if model_gemini:\n",
    "    for key, prompt in predefined_prompts.items():\n",
    "        try:\n",
    "            response = model_gemini.generate_content(prompt)\n",
    "            precomputed_responses[key] = response.text.strip()\n",
    "        except Exception as e:\n",
    "            precomputed_responses[key] = f\"⚠️ Gemini error: {e}\"\n",
    "else:\n",
    "    for key in predefined_prompts:\n",
    "        precomputed_responses[key] = \"❌ Gemini not available. Check API key.\"\n",
    "\n",
    "# ===================== Gradio Interface ===================== #\n",
    "def get_response(prompt_key):\n",
    "    return precomputed_responses.get(prompt_key, \"❌ Invalid selection.\")\n",
    "\n",
    "logging.getLogger(\"gradio\").setLevel(logging.ERROR)\n",
    "\n",
    "with gr.Blocks(css=\".full-width .scroll-hide { overflow-x: hidden !important; }\") as demo:\n",
    "    gr.Markdown(\"## 💧 Water Potability Model Evaluation & Gemini Insights\")\n",
    "\n",
    "    gr.Markdown(\"### 📊 Model Evaluation Metrics\")\n",
    "    gr.Dataframe(value=metrics_df, label=\"Performance Summary\", interactive=False, render=True, elem_classes=\"full-width\")\n",
    "\n",
    "    gr.Markdown(\"### 🤖 Ask Gemini About the Results\")\n",
    "    prompt_selector = gr.Radio(\n",
    "        list(predefined_prompts.keys()),\n",
    "        label=\"Select a Prompt\",\n",
    "        interactive=True\n",
    "    )\n",
    "\n",
    "    response_box = gr.Markdown()\n",
    "    prompt_selector.change(fn=get_response, inputs=prompt_selector, outputs=response_box)\n",
    "\n",
    "    demo.launch(share=True, inline=False, debug=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPI5S1Up+AyuDsjy/z2XUBQ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
